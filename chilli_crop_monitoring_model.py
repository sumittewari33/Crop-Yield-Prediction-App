# -*- coding: utf-8 -*-
"""Chilli crop monitoring model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pysa1EfRStEnAoJm_74DRhAoaIE5XpfL
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import mean_squared_error, r2_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

# Load the data from 'data.csv'
data = pd.read_csv('advanced_chilli_crop_data.csv')

# Feature and target selection
X = data.drop(columns=['yield'])  # Replace 'yield' with your target column if different
y = data['yield']
X = pd.get_dummies(X, drop_first=True)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
pca = PCA(n_components=0.95)
X_pca = pca.fit_transform(X_scaled)
print("Explained Variance Ratio:", pca.explained_variance_ratio_)
rf = RandomForestRegressor(random_state=42)
gb = GradientBoostingRegressor(random_state=42)

param_grid_rf = {'n_estimators': [100, 200], 'max_depth': [10, 15], 'min_samples_split': [2, 5]}
param_grid_gb = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}
grid_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_gb = GridSearchCV(estimator=gb, param_grid=param_grid_gb, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)

grid_rf.fit(X_pca, y)
grid_gb.fit(X_pca, y)

best_rf = grid_rf.best_estimator_
best_gb = grid_gb.best_estimator_
ensemble_model = VotingRegressor([('rf', best_rf), ('gb', best_gb)])
ensemble_model.fit(X_pca, y)
cv_scores = cross_val_score(ensemble_model, X_pca, y, cv=5, scoring='neg_mean_squared_error')
rmse_scores = np.sqrt(-cv_scores)
print("Cross-Validation RMSE Scores:", rmse_scores)
print("Mean RMSE:", rmse_scores.mean())
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)
ensemble_model.fit(X_train, y_train)
y_pred = ensemble_model.predict(X_test)

print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Actual Yield")
plt.ylabel("Predicted Yield")
plt.title("Actual vs Predicted Yield")
plt.show()

joblib.dump(scaler, "scaler.pkl")
joblib.dump(ensemble_model, "red_chilli_crop_advanced_model.pkl")

def predict_yield(new_data):
    scaler = joblib.load("scaler.pkl")
    model = joblib.load("red_chilli_crop_advanced_model.pkl")
    new_data_scaled = scaler.transform(new_data)
    new_data_pca = pca.transform(new_data_scaled)
    return model.predict(new_data_pca)

new_data = pd.DataFrame({
    'temperature': [30],
    'rainfall': [100],
    # Add other features here to match the original dataset
})

# Preprocess new data for dummy variables
new_data_dummies = pd.get_dummies(new_data, drop_first=True).reindex(columns=X.columns, fill_value=0)
predicted_yield = predict_yield(new_data_dummies)
print("Predicted Yield:", predicted_yield)

from google.colab import files
python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import mean_squared_error, r2_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

# Load the data from 'data.csv'
data = pd.read_csv('advanced_chilli_crop_data.csv')

# Feature and target selection
X = data.drop(columns=['yield'])  # Replace 'yield' with your target column if different
y = data['yield']
X = pd.get_dummies(X, drop_first=True)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
pca = PCA(n_components=0.95)
X_pca = pca.fit_transform(X_scaled)
print("Explained Variance Ratio:", pca.explained_variance_ratio_)
rf = RandomForestRegressor(random_state=42)
gb = GradientBoostingRegressor(random_state=42)

param_grid_rf = {'n_estimators': [100, 200], 'max_depth': [10, 15], 'min_samples_split': [2, 5]}
param_grid_gb = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}
grid_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_gb = GridSearchCV(estimator=gb, param_grid=param_grid_gb, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)

grid_rf.fit(X_pca, y)
grid_gb.fit(X_pca, y)

best_rf = grid_rf.best_estimator_
best_gb = grid_gb.best_estimator_
ensemble_model = VotingRegressor([('rf', best_rf), ('gb', best_gb)])
ensemble_model.fit(X_pca, y)
cv_scores = cross_val_score(ensemble_model, X_pca, y, cv=5, scoring='neg_mean_squared_error')
rmse_scores = np.sqrt(-cv_scores)
print("Cross-Validation RMSE Scores:", rmse_scores)
print("Mean RMSE:", rmse_scores.mean())
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)
ensemble_model.fit(X_train, y_train)
y_pred = ensemble_model.predict(X_test)

print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Actual Yield")
plt.ylabel("Predicted Yield")
plt.title("Actual vs Predicted Yield")
plt.show()

joblib.dump(scaler, "scaler.pkl")
joblib.dump(ensemble_model, "red_chilli_crop_advanced_model.pkl")

def predict_yield(new_data):
    scaler = joblib.load("scaler.pkl")
    model = joblib.load("red_chilli_crop_advanced_model.pkl")
    new_data_scaled = scaler.transform(new_data)
    new_data_pca = pca.transform(new_data_scaled)
    return model.predict(new_data_pca)

new_data = pd.DataFrame({
    'temperature': [30],
    'rainfall': [100],
    # Add other features here to match the original dataset
})

# Preprocess new data for dummy variables
new_data_dummies = pd.get_dummies(new_data, drop_first=True).reindex(columns=X.columns, fill_value=0)
predicted
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import mean_squared_error, r2_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

# Load the data from 'data.csv'
data = pd.read_csv('advanced_chilli_crop_data.csv')

# Feature and target selection
X = data.drop(columns=['yield'])  # Replace 'yield' with your target column if different
y = data['yield']
X = pd.get_dummies(X, drop_first=True)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
pca = PCA(n_components=0.95)
X_pca = pca.fit_transform(X_scaled)
print("Explained Variance Ratio:", pca.explained_variance_ratio_)
rf = RandomForestRegressor(random_state=42)
gb = GradientBoostingRegressor(random_state=42)

param_grid_rf = {'n_estimators': [100, 200], 'max_depth': [10, 15], 'min_samples_split': [2, 5]}
param_grid_gb = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}
grid_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_gb = GridSearchCV(estimator=gb, param_grid=param_grid_gb, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)

grid_rf.fit(X_pca, y)
grid_gb.fit(X_pca, y)

best_rf = grid_rf.best_estimator_
best_gb = grid_gb.best_estimator_
ensemble_model = VotingRegressor([('rf', best_rf), ('gb', best_gb)])
ensemble_model.fit(X_pca, y)
cv_scores = cross_val_score(ensemble_model, X_pca, y, cv=5, scoring='neg_mean_squared_error')
rmse_scores = np.sqrt(-cv_scores)
print("Cross-Validation RMSE Scores:", rmse_scores)
print("Mean RMSE:", rmse_scores.mean())
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)
ensemble_model.fit(X_train, y_train)
y_pred = ensemble_model.predict(X_test)

print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Actual Yield")
plt.ylabel("Predicted Yield")
plt.title("Actual vs Predicted Yield")
plt.show()

joblib.dump(scaler, "scaler.pkl")
joblib.dump(ensemble_model, "red_chilli_crop_advanced_model.pkl")

def predict_yield(new_data):
    scaler = joblib.load("scaler.pkl")
    model = joblib.load("red_chilli_crop_advanced_model.pkl")
    new_data_scaled = scaler.transform(new_data)
    new_data_pca = pca.transform(new_data_scaled)
    return model.predict(new_data_pca)

new_data = pd.DataFrame({
    'temperature': [30],
    'rainfall': [100],
    # Add other features here to match the original dataset
})

# Preprocess new data for dummy variables
new_data_dummies = pd.get_dummies(new_data, drop_first=True).reindex(columns=X.columns, fill_value=0)
predicted
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import mean_squared_error, r2_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

# Load the data from 'data.csv'
data = pd.read_csv('advanced_chilli_crop_data.csv')

# Feature and target selection
X = data.drop(columns=['yield'])  # Replace 'yield' with your target column if different
y = data['yield']
X = pd.get_dummies(X, drop_first=True)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
pca = PCA(n_components=0.95)
X_pca = pca.fit_transform(X_scaled)
print("Explained Variance Ratio:", pca.explained_variance_ratio_)
rf = RandomForestRegressor(random_state=42)
gb = GradientBoostingRegressor(random_state=42)

param_grid_rf = {'n_estimators': [100, 200], 'max_depth': [10, 15], 'min_samples_split': [2, 5]}
param_grid_gb = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}
grid_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_gb = GridSearchCV(estimator=gb, param_grid=param_grid_gb, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)

grid_rf.fit(X_pca, y)
grid_gb.fit(X_pca, y)

best_rf = grid_rf.best_estimator_
best_gb = grid_gb.best_estimator_
ensemble_model = VotingRegressor([('rf', best_rf), ('gb', best_gb)])
ensemble_model.fit(X_pca, y)
cv_scores = cross_val_score(ensemble_model, X_pca, y, cv=5, scoring='neg_mean_squared_error')
rmse_scores = np.sqrt(-cv_scores)
print("Cross-Validation RMSE Scores:", rmse_scores)
print("Mean RMSE:", rmse_scores.mean())
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)
ensemble_model.fit(X_train, y_train)
y_pred = ensemble_model.predict(X_test)

print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Actual Yield")
plt.ylabel("Predicted Yield")
plt.title("Actual vs Predicted Yield")
plt.show()

joblib.dump(scaler, "scaler.pkl")
joblib.dump(ensemble_model, "red_chilli_crop_advanced_model.pkl")

def predict_yield(new_data):
    scaler = joblib.load("scaler.pkl")
    model = joblib.load("red_chilli_crop_advanced_model.pkl")
    new_data_scaled = scaler.transform(new_data)
    new_data_pca = pca.transform(new_data_scaled)
    return model.predict(new_data_pca)

new_data = pd.DataFrame({
    'temperature': [30],
    'rainfall': [100],
    # Add other features here to match the original dataset
})

# Preprocess new data for dummy variables
new_data_dummies = pd.get_dummies(new_data, drop_first=True).reindex(columns=X.columns, fill_value=0)
predicted
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import mean_squared_error, r2_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

# Load the data from 'data.csv'
data = pd.read_csv('advanced_chilli_crop_data.csv')

# Feature and target selection
X = data.drop(columns=['yield'])  # Replace 'yield' with your target column if different
y = data['yield']
X = pd.get_dummies(X, drop_first=True)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
pca = PCA(n_components=0.95)
X_pca = pca.fit_transform(X_scaled)
print("Explained Variance Ratio:", pca.explained_variance_ratio_)
rf = RandomForestRegressor(random_state=42)
gb = GradientBoostingRegressor(random_state=42)

param_grid_rf = {'n_estimators': [100, 200], 'max_depth': [10, 15], 'min_samples_split': [2, 5]}
param_grid_gb = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}
grid_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_gb = GridSearchCV(estimator=gb, param_grid=param_grid_gb, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)

grid_rf.fit(X_pca, y)
grid_gb.fit(X_pca, y)

best_rf = grid_rf.best_estimator_
best_gb = grid_gb.best_estimator_
ensemble_model = VotingRegressor([('rf', best_rf), ('gb', best_gb)])
ensemble_model.fit(X_pca, y)
cv_scores = cross_val_score(ensemble_model, X_pca, y, cv=5, scoring='neg_mean_squared_error')
rmse_scores = np.sqrt(-cv_scores)
print("Cross-Validation RMSE Scores:", rmse_scores)
print("Mean RMSE:", rmse_scores.mean())
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)
ensemble_model.fit(X_train, y_train)
y_pred = ensemble_model.predict(X_test)

print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Actual Yield")
plt.ylabel("Predicted Yield")
plt.title("Actual vs Predicted Yield")
plt.show()

joblib.dump(scaler, "scaler.pkl")
joblib.dump(ensemble_model, "red_chilli_crop_advanced_model.pkl")

def predict_yield(new_data):
    scaler = joblib.load("scaler.pkl")
    model = joblib.load("red_chilli_crop_advanced_model.pkl")
    new_data_scaled = scaler.transform(new_data)
    new_data_pca = pca.transform(new_data_scaled)
    return model.predict(new_data_pca)

new_data = pd.DataFrame({
    'temperature': [30],
    'rainfall': [100],
    # Add other features here to match the original dataset
})

# Preprocess new data for dummy variables
new_data_dummies = pd.get_dummies(new_data, drop_first=True).reindex(columns=X.columns, fill_value=0)
predicted

import streamlit as st
import pickle
import numpy as np

# Load your trained model
with open("red_chilli_crop_advanced_model.pkl", "rb") as file:
    model = pickle.load(file)

# Define a prediction function
def predict_yield(temperature, rainfall, humidity, soil_moisture, nitrogen, phosphorus, potassium, pest_incidence, disease_incidence):
    # Input array for the model
    input_data = np.array([[temperature, rainfall, humidity, soil_moisture, nitrogen, phosphorus, potassium, pest_incidence, disease_incidence]])
    yield_prediction = model.predict(input_data)
    return yield_prediction[0]

# Streamlit app layout
st.title("Red Chili Crop Yield Prediction")
st.write("Enter crop parameters below to predict the yield:")

# Input widgets
temperature = st.slider("Temperature (°C)", 15, 45, 25)
rainfall = st.slider("Rainfall (mm)", 0, 500, 100)
humidity = st.slider("Humidity (%)", 0, 100, 50)
soil_moisture = st.slider("Soil Moisture (%)", 0, 50, 20)
nitrogen = st.slider("Nitrogen (mg/kg)", 0, 100, 50)
phosphorus = st.slider("Phosphorus (mg/kg)", 0, 50, 20)
potassium = st.slider("Potassium (mg/kg)", 0, 100, 50)
pest_incidence = st.slider("Pest Incidence (%)", 0, 30, 5)
disease_incidence = st.slider("Disease Incidence (%)", 0, 25, 3)

# Predict yield button
if st.button("Predict Yield"):
    result = predict_yield(temperature, rainfall, humidity, soil_moisture, nitrogen, phosphorus, potassium, pest_incidence, disease_incidence)
```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import mean_squared_error, r2_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

# Load the data from 'data.csv'
data = pd.read_csv('advanced_chilli_crop_data.csv')

# Feature and target selection
X = data.drop(columns=['yield'])  # Replace 'yield' with your target column if different
y = data['yield']
X = pd.get_dummies(X, drop_first=True)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
pca = PCA(n_components=0.95)
X_pca = pca.fit_transform(X_scaled)
print("Explained Variance Ratio:", pca.explained_variance_ratio_)
rf = RandomForestRegressor(random_state=42)
gb = GradientBoostingRegressor(random_state=42)

param_grid_rf = {'n_estimators': [100, 200], 'max_depth': [10, 15], 'min_samples_split': [2, 5]}
param_grid_gb = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}
grid_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_gb = GridSearchCV(estimator=gb, param_grid=param_grid_gb, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)

grid_rf.fit(X_pca, y)
grid_gb.fit(X_pca, y)

best_rf = grid_rf.best_estimator_
best_gb = grid_gb.best_estimator_
ensemble_model = VotingRegressor([('rf', best_rf), ('gb', best_gb)])
ensemble_model.fit(X_pca, y)
cv_scores = cross_val_score(ensemble_model, X_pca, y, cv=5, scoring='neg_mean_squared_error')
rmse_scores = np.sqrt(-cv_scores)
print("Cross-Validation RMSE Scores:", rmse_scores)
print("Mean RMSE:", rmse_scores.mean())
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)
ensemble_model.fit(X_train, y_train)
y_pred = ensemble_model.predict(X_test)

print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Actual Yield")
plt.ylabel("Predicted Yield")
plt.title("Actual vs Predicted Yield")
plt.show()

joblib.dump(scaler, "scaler.pkl")
joblib.dump(ensemble_model, "red_chilli_crop_advanced_model.pkl")

def predict_yield(new_data):
    scaler = joblib.load("scaler.pkl")
    model = joblib.load("red_chilli_crop_advanced_model.pkl")
    new_data_scaled = scaler.transform(new_data)
    new_data_pca = pca.transform(new_data_scaled)
    return model.predict(new_data_pca)

new_data = pd.DataFrame({
    'temperature': [30],
    'rainfall': [100],
    # Add other features here to match the original dataset
})

# Preprocess new data for dummy variables
new_data_dummies = pd.get_dummies(new_data, drop_first=True).reindex(columns=X.columns, fill_value=0)
predicted
import pickle

# Load the model
with open('model.pkl', 'rb') as f:
    model = pickle.load(f)

# App logic
st.title("Crop Yield Prediction")
# Add input fields and predictions
user_input = st.text_input("Enter input data for prediction")
if user_input:
    # Assuming the model expects numeric input
    prediction = model.predict([[float(user_input)]])
    st.write(f"Predicted yield: {prediction[0]}")